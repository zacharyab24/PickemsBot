During Counter-Strike majors, valve release a thing called Pick'ems. Pick'ems are a pretty simple concept, they allow users to predict which teams they think will win (or lose) in each stage of the major. A major is broken up into two different sections, the Swiss tournament (usually two or three rounds) and the finals (a single elimination tournament). In a Swiss tournament, 16 teams compete, with each team having three lives, and the goal of winning three matches. The 8 teams that achieve 3 three wins move onto the next stage of the tournament, whilst the other 8 teams are eliminated. In a finals tournament, the teams compete to move onto the next bracket, with the winning team progressing and the losing team being eliminated. This happens until one team emerges victorious and wins the tournament.

During Pick'ems, viewers have a coin, which starts at bronze tier, and levels up depending on how successful their picks were, with each tier giving you in game rewards. The ultimate goal of Pick'ems is to get a Diamond coin, which very few viewers achieve. When watching my first major in March of 2024, myself and a few mates in discord had a friendly competition going to see who did the best. After each day of matches, I would look at each person's picks and give an update on how everyone was doing. This quickly got repetitive and tedious to do, then it hit me. I am a computer science student, I love programming, why don't I make a discord bot that can do this automatically, so that's what I did. Originally, this was going to be a very simple python script I could run once a day, but things devolved a lot from there. This article explores the issues, challenges and successes that I experienced over the last 15 months developing what was supposed to be this simple python script.

## Data Collection
The first course of action was finding a way to get match results. Of course I could manually input the results of each match, but where's the fun in that. Additionally, due to being located in Australia, and matches being on the other side of the world (Copenhagen for the first major), I would not necessarily be awake when matches occurred, and I might not be awake when others were wanting to check their results. It was pretty obvious we were going to need some way of automatically getting data. My first thought was to scrape HLTV (The go to website for counter-strike esports), or see if they were making any API calls to get their data, however this idea was quickly shut down as I couldn't see any API requests being made (at least meaningful ones) from my client to their servers. Scraping and parsing the HTML didn't prove useful either as my attempts were regularly blocked, and even when I did get a response, nothing meaningful was returned. It was clear I was going to need to find another way to get my data.

The next site I stumbled upon was Liquipedia. Liquipedia is an online wiki maintained by Team Liquid, a popular esports organisation. The site is nowhere near as nice to use as HLTV, however they had all of the data I needed, and being a static wiki, I could very easily scrape the data I needed. Alright, we now had a reliable data source, it was onto building the bot.

## Version 1
Now that we had a reliable way to access data, it was onto parsing that data and storing it and user data in a meaningful way. The BeautifulSoup4 library was chosen for parsing data for its ease of use and simplistic nature. With a bit of digging through the HTML I was able to find the exact data I needed on the site, and parse this into something I could actually use. For Swiss tournaments, there is a nice table showing a teams score, who they played, and whether they won or lost. Since all we cared about was the team name and their score, we could easily extract this and put it in a Python dictionary where `dict[team_name] = score`. We could then compare this to a user input and check how that user's prediction was going.

 Now that we had a way to get external data, we needed an interface where users were going to be able to input their predictions and check their results. This was achieved using the [discordpy](https://discordpy.readthedocs.io/en/stable/index.html) library for creating a discord bot. Implementing this was relatively simple, with the bot listening for a message, and if the message met a criteria, running a function in the script and posting a message to the discord channel. I opted to use the `$` operator for my functions as integrating with `/` commands was a lot more difficult, and at this point i was very sleep deprived. I built a `$set` command which would have the users input 10 team names after it in order to set their predictions. In the Pick'ems predictor, you are required to set 10 teams, the 2 teams you think will go 3-0, the 6 other teams you think will progress to the next stage of the tournament, and the 2 teams you think will go 0-3.

So now we have a way to fetch match results, and get user predictions, next we need a way to calculate how the user is doing. This was pretty simple, a user has 10 predictions, we can just loop through and see if:
- the teams they had for 3-0 have any loses, if they did it was a failure
- the teams they had for 0-3 have any wins, if they did it was a failure
- the teams they had to progress have 3 loses, if they did it was a failure
Additionally, to prevent any false readings, if the matches played was less than 5, and none of the above conditions were met, the prediction was given a pending result. We could also use this result to give the player an overall score. If they had a successful prediction they got a point, if they had a failed prediction they lost a point. This could be used to rank users in a leaderboard fashion. 

We have now gotten the core functionality of the bot done, at least for the Swiss style tournament, however there was a slight issue. If the bot was stopped, we would lose a user's predictions, and no one wants to have to type out the name of 10 teams every time they want to check their results, so some sort of persistent storage was needed. 

## Database
At this point in my studies, I have only ever worked with SQL Server and TSQL, which I could have used for this project, however I didn't really want to go through the effort of setting this up, especially as I didn't need anything that sophisticated or large. I'd also wanted to experiment with something new as isn't that the whole point of doing these side projects. I chose MongoDB, purely because it was something new, being a NoSQL system and non-relational. I was able to set up a free cloud based database through Mongo Atlas, which was perfect for my application which was going to have minimal traffic. 

The database design was very simple, have a collection for user predictions, so that when the `$check` command is run, we can pull the user prediction from the database based upon their discord id, which was grabbed when the bot was checking the message. We could also store results, however some functionality to update this was going to be required and thus this wasn't added for the time being.

We now had a working, albeit very buggy prototype that I'd stayed up most of the night working on. I left the program running on my PC, wrote a quick message in our discord server of how to use the bot and went to sleep as the sun started to rise. What I woke up to was a number of messages asking why it didn't work...

## The Fallout
When I awoke later that day, the bot had crashed. I hadn't set up any redundancy or proper error checking so one invalid input and the whole thing came down. My day was then focused on error handling, better input validation and general bug fixes to try and keep the thing online whilst I had a swarm of users actively trying to bring it down. I added a feature where user's could see a list of all valid team names, then when the user tried to set their prediction the team names would be validated. This caused a number of issues as a lot of team names are multiple words, and previously our check for a valid number of teams was `len(message) == 11`. This meant we needed a new way to split team names and strings. The easiest thing I could think of was to have users put `"` around the team name and split on quote marks. This worked but introduced a new issue. On the desktop client, the input for quote marks is `"`, however on the mobile version, the input is `“` and `”` which took a while to discover and debug. After a day or so of bug fixes, we now had a much smoother experience. There were still a decent amount of bugs and the experience was somewhat limited, but we had achieved the set out goal and I no longer had to manually check how user's were doing.

## Finals
The finals section of the tournament required a complete rewrite of the bot. At this stage, most things, including our data source were hard coded for a specific page on Liquipedia. Instead of doing the smart thing, and making some abstract class with extends functions for both Swiss and finals, I decided to just make another bot, which used the same API key and just had a new scraping method and check algorithm. This was relatively simple to implement, the data was stored in a different shaped table, however getting the results I needed was still pretty simple. For checking this time we just needed to look at each of the 3 stages in the single elimination bracket:
- Quarter finals
- Semi finals
- Grand final
For the Pick'ems input, a user is required to pick the teams they think will win each stage, so we would need to collect 7 inputs in total: quarter final winner 1, 2, 3 and 4, semi final winner 1 and 2, and grand final winner. This seems simple enough, however trying to explain to users how to input this in a nice way was not so easy, and the overall experience was a bit cumbersome. The team that the user though was going to win the overall tournament would need to be entered 4 times which was also a bit redundant, however it was kept for the time being

A new feature was also added during this stage, upcoming matches. Using the `$upcoming` command, a message was sent featuring the upcoming matches for that day. This data was obtained by scraping a different part of Liquipedia's site which listed all upcoming matches. The results were then filtered to show only matches belonging to the major, and limited to results in this round. The result was a Unix epoch timestamp which allowed me to utilise discord's markdown features to localise the match time. This meant that our friend who lived in another time zone, didn't have to convert the match times to his own time zone, which was a nice originally unintended feature. 

By now the bot was pretty feature complete, and fulfilled all of the original goals. I ended up deploying the bot to a docker container so it could be quickly spun back up if it crashed and didn't need to always keep a terminal open on my PC. Obviously this still had the issue of if I turned by PC off the bot would go down, but the tournament was basically finished which made this a problem for another day

# Version 2
Nearly 9 months pass, and as we come into December 2024, the next major is coming up. Our small user base is already excited for the Pick'ems Bot to make a return so I decide its time to step up my game. There were a number of issues with the previous bot that I wanted to fix, mostly revolving around reliability. I decided it would be a good idea to rewrite the whole thing in GO, and have a single bot, rather than 2 for the application. The choice for GO came around similarly to the choice for MongoDB, I just wanted to experiment with something new. I'd heard good things about GO, and wanted to move away from the Java and Python that my studies had focused on.

The logic for the bot was similar, with some minor changes being required for different source pages for our data, and different libraries for data scraping. The conversion from Python to GO wasn't overly difficult, however took some time due to being unfamiliar with the language. I also decided to add a caching feature to the bot, where instead of scraping Liquipedia and processing the data every time the `$check` or `$leaderboard` functions were called, we would store them in the database with a 15 minute TTL. This greatly reduced processing times with the only caveat being that if the command was run just before a match page was updated, users would have to wait 15 minutes to see the results unless I went and dropped the document from the DB.

I used command line flags to parse data into the bot at run time. This allowed me to specify the database name, url we need to scrape, name of the tournament which was used in database naming, if I was running the test version or production version of the bot and a few other flags. This was a big step up from modifying the hard coded values for each new stage of the tournament.

This version of the bot was still very clunky to use, and had a few issues, however it was a lot more stable from being forced to error handle with Go. The code base was also pretty unclean as I was unfamiliar with conventions for GO. I decided to deploy the bot to Azure this time, instead of running locally on my PC. I used a free credit I got for Azure through my university so the bot was free to run. For the 3 weeks the major went on, the bot only cost a couple of dollars to run anyway so this wouldn't have been a major issue.

## Version 3
We now transition into May 2025. By this point, I thought running the bot for the upcoming major was going to be simple, clone the repo, update the pages we were scraping and clicking run, however this was not the case. For some unknown reason, Liquipedia changed their pages to use "Stage 1", "Stage 2", "Stage 3" and "Playoffs" instead of "Opening Stage", "Elimination Stage" and "Playoff Stage". No biggie, I'll just update the references to these in the code base and all will be fine. Well this didn't end up working. I had way too many hard coded references in the code base, and the bot was more unstable than ever. To make things worse, I started getting my scraping requests blocked when trying to fetch data. It was looking like the days of the project were drawing to a close. Without a reliable way to get match data, the bot wasn't able to function. And with the rename of page names, came changes to the underlying HTML code that I was parsing before. Just when I was ready to give up, I got a DM from a close friend. He sent me a URL for the LiquipediaDB API. I had previously overlooked this as when I looked at the documentation, I could only find things for creating and modifying pages on the site, not for getting data. However when reading about the LiquipediaDB, I noticed that you had to request permission to gain access to the full feature set of the API, so that's what I did

A few days later, I had access to the API, and started to read the documentation to find if what I required was even achievable. After a few hours of tinkering, I had managed to generate an API request that could return all of the data I required. Unfortunately, the API didn't return the nice, simple to use table I was scraping before, however I could get all of the data I needed. I decided it was time for a complete refactor of the bot to make the code base easier to read, more fault tolerant and polymorphic for different tournament structures, instead of the hard coded mess it previously was.

I decided to divide the project into two sections: and API and the Bot. The original plan was to make a RESTful API for which I could call endpoints to get the data I needed from within the bot. This would also allow me to extend the project into a web app if I wanted. However something went wrong with the design and this never ended up happening. I can't explain what went wrong, I just ended up with a bunch of functions that serve the data required. There is no web server, or HTTP requests being sent, the functions are just called like any other library, so I guess I made a library not an API.

Regardless, I had a new goal, get the bot as extensible and feature rich over the next week before the major started. I had a reliable way of fetching data and storing it. Now I had to focus on my goal of making the bot polymorphic. I wanted the bot to be automatically be able to fetch data for a Swiss or Single Elimination tournament without me needing to tell it at run time what type it was. This required making several interfaces for different components, with structs for each type of tournament. Whilst this added a lot to the code base, the results were amazing. There were still some limitations, mostly that there is a hard coded limitation for Single Elimination tournaments of 32 teams. This limit is easy enough to modify, there is just a couple of maps in the program that need to be updated, and the largest Single Elimination tournament I could find in recent times was a BO16 anyway so I figured this was a reasonable compromise. 

Getting user input for Swiss tournaments was still the same, however I decided it was time to optimise the finals input. Instead of needing 7 teams, we only actually require 4: the two teams that win the quarter finals but lose the semi finals, the team that wins the semi finals but loses the grand final, and the team that wins the grand final. This has the same functionality of the previous 7 team input, but requires each team to only be input once.

I also decided it was time to fix another major issue with getting user input, team matching. Previously it was required that the entire team name be entered, which meant if a typo was made, or only the "primary" team name was entered the input would get rejected. This is particularly an issue because a lot of teams have the words "Team" or "Gaming" in them. I decided added fuzzy matching for user inputs would be a great idea, and for the most part it was. It allowed for typos and abbreviations to be used, and the user base loved this change. They no longer had to ensure the name was 100% correct according to how Liquipedia determined team names should be. The only issue occurred from "OG". OG is the entire name of a German eSports team. No "Team OG" or "OG Gaming", just OG. This two letter team name caused some issues with the [fuzzy search](https://github.com/lithammer/fuzzysearch)  library I was using. The only conflict it had was with "Lynn Vision Gaming", and I still don't know why this conflict occurred, but apparently the input "OG" is a better match for "Lynn Vision Gaming" than "OG". To fix this I decided to add an exact match check if the fuzzy search gave more than one result.

Over the week I slowly refactored the entire bot into the two separate components as I had originally planned, however one being a library more than a full blown API like I had originally planned. I added some caching features to align with the API usage requirements for the LiquipediaDB. The primary goal here was to fix the timing issue set by the original 15 minute cache. I added a dynamic approach where if there was currently an ongoing match, we would set the TTL to 3 minutes, else it would be 30 minutes. This worked well to ensure we always had up to date data without exceeding API usage.

Instead of deploying this bot to Azure again, I decided to once again host locally. Since originally creating the bot, I have setup a home server, so I thought it would be a great idea to host locally since I didn't have any free azure credits this time around. I also decided to host the DB locally instead of using the free online hosting to reduce latency. Once again I used docker to deploy the bot, however this time I used GitHub actions to automatically update the bot when I wanted to make changes. I set up an action so that on push to main, GitHub SSH's into my server with TailScale, pulls the latest version of the code and builds a docker container. Within a few minutes of pushing to main, the new docker container is running and the updated version of my bot is deployed with only a couple of seconds of down time. 

This version of the bot removed using flags at run time as these were harder to customise with the continuous integration setup. Instead the values were transitioned into environmental variables stored in the `.env` file with along with the API keys and database connection string.

One of the main goals for this iteration of the bot was making it as stable as possible, and after the conclusion of the Austin Major in June 2025 I can conclude this goal was achieved. The bot had next to no crashes this go round, and the users were actively trying to break it.

## Where To Next
As of writing this, we are 6 months away from the next major, so progress on development has stalled. I have a couple of ideas for new features, however we will see how this pans out when that time comes. With the changes made in V3, the bot should now just be as simple as updating the tournament URL and rebuilding the docker container, with no other changed needed, so long as the LiquipediaDB API doesn't have any major changes in the next 6 months.

The new ideas for features I have is to add a previous match feature, where match results for the games that have occurred in the last 24 hours are viewable, preventing the need to go to Liquipedia or HLTV to see who beat who. This should be a relatively easy feature to add as most of the required data is already being stored in the DB. Additionally I'd like to optimise the leaderboard functionality as currently every time it is run, it needs to compute the score for each user with saved results. Only having a handful of users currently means this is not a big deal, however being able to scale the application would be nice.

If you would like to check out the bot, you can find it's repo [here](https://github.com/zacharyab24/PickemsBot/) 
